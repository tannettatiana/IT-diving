{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cffdd5d6-3712-45d2-b5c0-cbb48b5f377d",
      "metadata": {
        "id": "cffdd5d6-3712-45d2-b5c0-cbb48b5f377d"
      },
      "source": [
        "# Обучение моделей в Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fc18f6a-31c9-4ff1-b7a7-02a7a13f85cd",
      "metadata": {
        "id": "2fc18f6a-31c9-4ff1-b7a7-02a7a13f85cd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from os.path import join as pjoin\n",
        "from shutil import rmtree\n",
        "\n",
        "import albumentations\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from accelerate import Accelerator\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import datasets\n",
        "\n",
        "from checkpointer import CheckpointSaver, load_checkpoint\n",
        "from dataset import CLASS_WEIGHTS, CustomVOCSegmentation, convert_label_to_color\n",
        "from deeplabv3plus.modeling import deeplabv3plus_resnet50\n",
        "from loss import CrossEntropyDiceLoss\n",
        "from metric import MeanIoU\n",
        "from train import count_pytorch_model_params, train\n",
        "from unet import UNet\n",
        "from unet_custom import CustomUNet\n",
        "from utils import seed_everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12069a41-bbcb-4292-931b-27c367515ef8",
      "metadata": {
        "id": "12069a41-bbcb-4292-931b-27c367515ef8"
      },
      "outputs": [],
      "source": [
        "seed_everything(42, torch_deterministic=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d17238-f92d-4347-a84e-91b2f37598bc",
      "metadata": {
        "id": "40d17238-f92d-4347-a84e-91b2f37598bc"
      },
      "source": [
        "## Аугментации"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0959cf2-ad28-4ae5-84f9-02fd7beb6190",
      "metadata": {
        "id": "b0959cf2-ad28-4ae5-84f9-02fd7beb6190"
      },
      "source": [
        "Трансформации/аугментации для исходных изображений и масок/таргетов.\n",
        "\n",
        "Аугментации для задач компьютерного хрения: https://albumentations.ai/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662c1e5a-ca36-4b9f-802a-da8e3786c5b3",
      "metadata": {
        "id": "662c1e5a-ca36-4b9f-802a-da8e3786c5b3"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 256\n",
        "MEAN = np.array([0.485, 0.456, 0.406])\n",
        "STD = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "train_transforms = albumentations.Compose(\n",
        "    [\n",
        "        albumentations.SmallestMaxSize(max_size=IMAGE_SIZE),\n",
        "        albumentations.CropNonEmptyMaskIfExists(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
        "        # albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
        "        albumentations.HorizontalFlip(p=0.5),\n",
        "        albumentations.ShiftScaleRotate(\n",
        "            shift_limit=0.05,\n",
        "            scale_limit=0.1,\n",
        "            rotate_limit=15,\n",
        "            p=0.5,\n",
        "        ),\n",
        "        albumentations.RandomCrop(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n",
        "        albumentations.OneOf(\n",
        "            [\n",
        "                albumentations.CLAHE(p=0.3),\n",
        "                albumentations.RandomBrightnessContrast(p=0.5),\n",
        "                albumentations.HueSaturationValue(p=0.3),\n",
        "            ],\n",
        "            p=0.8,\n",
        "        ),\n",
        "        albumentations.Normalize(mean=MEAN, std=STD),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = albumentations.Compose(\n",
        "    [\n",
        "        albumentations.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0),\n",
        "        albumentations.Normalize(mean=MEAN, std=STD),\n",
        "        ToTensorV2(),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a88cc6ba-7bbf-403f-acca-b6b1e6978d45",
      "metadata": {
        "id": "a88cc6ba-7bbf-403f-acca-b6b1e6978d45"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b0f487b-abee-4652-b95b-cb1affbe6c34",
      "metadata": {
        "id": "7b0f487b-abee-4652-b95b-cb1affbe6c34"
      },
      "source": [
        "Набор данных Pascal VOC. Рассмотрим его версию для задачи сегментации.\n",
        "\n",
        "Сайт: http://host.robots.ox.ac.uk/pascal/VOC/\n",
        "\n",
        "Лидерборд за 2012 год: http://host.robots.ox.ac.uk:8080/leaderboard/displaylb_main.php?challengeid=11&compid=5\n",
        "\n",
        "При тех или иных проблемах со скачиванием с сайта соревнования, скачайте и распакуйте архив в папку `data` (`data/VOCdevkit`) отсюда: https://disk.yandex.ru/d/1jS3yBBN7YdZ-w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a88e21f6-543f-47a2-97ef-781a0a997449",
      "metadata": {
        "id": "a88e21f6-543f-47a2-97ef-781a0a997449"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomVOCSegmentation(\n",
        "    root=\"../data\",\n",
        "    year=\"2012\",\n",
        "    image_set=\"train\",\n",
        "    download=False,  # True\n",
        "    transform=train_transforms,  # transform, not transforms!\n",
        ")\n",
        "\n",
        "val_dataset = CustomVOCSegmentation(\n",
        "    root=\"../data\",\n",
        "    year=\"2012\",\n",
        "    image_set=\"val\",\n",
        "    download=False,\n",
        "    transform=val_transforms,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20f09949-7e66-43d9-824b-0595a09f3a02",
      "metadata": {
        "id": "20f09949-7e66-43d9-824b-0595a09f3a02"
      },
      "outputs": [],
      "source": [
        "image, target = train_dataset[0]\n",
        "\n",
        "image_orig = image * STD[:, None, None] + MEAN[:, None, None]\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(9, 18))\n",
        "ax[0].imshow(image_orig.numpy().transpose(1, 2, 0) + 1e-5)\n",
        "ax[1].imshow(image.numpy().transpose(1, 2, 0))\n",
        "ax[2].imshow(convert_label_to_color(target.numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc77e07d-9b6c-4ee7-a4ac-bc37b6b77344",
      "metadata": {
        "id": "bc77e07d-9b6c-4ee7-a4ac-bc37b6b77344"
      },
      "source": [
        "## UNet model\n",
        "\n",
        "Статья: https://arxiv.org/abs/1505.04597"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73a84d99-23f3-45a7-8ecd-cafcaab21224",
      "metadata": {
        "id": "73a84d99-23f3-45a7-8ecd-cafcaab21224"
      },
      "outputs": [],
      "source": [
        "model = UNet(in_channels=3, out_channels=21)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a77d6128-a241-4e0b-8cfa-9b8636b5f5c1",
      "metadata": {
        "id": "a77d6128-a241-4e0b-8cfa-9b8636b5f5c1"
      },
      "outputs": [],
      "source": [
        "count_pytorch_model_params(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b22de3-372a-48d9-ac36-95ac41dbee39",
      "metadata": {
        "id": "b2b22de3-372a-48d9-ac36-95ac41dbee39"
      },
      "source": [
        "## Accelerator"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdfe33d9-cce0-4373-ade0-6395cc8492a5",
      "metadata": {
        "id": "bdfe33d9-cce0-4373-ade0-6395cc8492a5"
      },
      "source": [
        "\"Accelerate — это библиотека, которая позволяет запускать один и тот же код PyTorch в любой распределенной конфигурации, добавляя всего четыре строки кода! Короче говоря, обучение и вывод в больших масштабах стали простыми, эффективными и адаптируемыми\". (c)\n",
        "\n",
        "Сайт: https://huggingface.co/docs/accelerate/index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67ca43ec-8ee3-4f92-9537-dba305bd18f8",
      "metadata": {
        "id": "67ca43ec-8ee3-4f92-9537-dba305bd18f8"
      },
      "outputs": [],
      "source": [
        "accelerator = Accelerator(cpu=False, mixed_precision=\"no\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de663eed-5747-4e58-b263-43a2f8a73800",
      "metadata": {
        "id": "de663eed-5747-4e58-b263-43a2f8a73800"
      },
      "source": [
        "## Checkpointer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06471151-0ca3-46c0-a3a0-f33b53853a75",
      "metadata": {
        "id": "06471151-0ca3-46c0-a3a0-f33b53853a75"
      },
      "source": [
        "Класс для сохранения наилучших версий модели в процессе обучения.\n",
        "\n",
        "См. класс `Checkpointer` в `train.py`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "658bce9e-3f9d-46ed-9950-1d0a66e5376f",
      "metadata": {
        "id": "658bce9e-3f9d-46ed-9950-1d0a66e5376f"
      },
      "source": [
        "## Обучаем модель"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e6fbee0-3925-494e-ae3e-a469042dd5a4",
      "metadata": {
        "id": "2e6fbee0-3925-494e-ae3e-a469042dd5a4"
      },
      "source": [
        "См. `train.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b04b29f-46ff-45aa-9cba-5a6f03c72470",
      "metadata": {
        "id": "7b04b29f-46ff-45aa-9cba-5a6f03c72470"
      },
      "outputs": [],
      "source": [
        "CLASSES_NUM = 21\n",
        "\n",
        "BACKBONE_NAME = \"resnet50\"\n",
        "\n",
        "LEARNING_RATE_SGD = 1e-3\n",
        "LEARNING_RATE_ADAM = 1e-4\n",
        "MIN_LEARNING_RATE = 1e-6\n",
        "WEIGHT_DECAY = 1e-4\n",
        "MOMENTUM_SGD = 0.9\n",
        "BETAS_ADAM = (0.9, 0.999)\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 4\n",
        "EPOCH_NUM = 100\n",
        "SCHEDULER_PATIENCE = 5\n",
        "SCHEDULER_GAMMA = 0.5\n",
        "CHECKPOINTS_DIR = \"checkpoints\"\n",
        "TENSORBOARD_DIR = \"tensorboard\"\n",
        "RM_CHECKPOINTS_DIR = False\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f24b17ad-99e7-4346-a5a4-38303c48221d",
      "metadata": {
        "scrolled": true,
        "id": "f24b17ad-99e7-4346-a5a4-38303c48221d"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "accelerator = Accelerator(cpu=DEVICE==\"cpu\", mixed_precision=\"no\")\n",
        "\n",
        "# model = UNet(in_channels=3, out_channels=CLASSES_NUM, bilinear=True)\n",
        "model = CustomUNet(backbone_name=BACKBONE_NAME, classes_num=CLASSES_NUM)\n",
        "# model = deeplabv3plus_resnet50()\n",
        "\n",
        "# model = load_checkpoint(\n",
        "#     model=model,\n",
        "#     load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\"),\n",
        "# )\n",
        "\n",
        "class_weights = torch.tensor(CLASS_WEIGHTS).to(DEVICE)\n",
        "# loss_fn = nn.CrossEntropyLoss(weight=class_weights, reduction=\"mean\", ignore_index=255)\n",
        "loss_fn = CrossEntropyDiceLoss(weight=class_weights, ignore_index=255)\n",
        "\n",
        "metric_fn = MeanIoU(classes_num=CLASSES_NUM, ignore_index=255).to(DEVICE)\n",
        "metric_fns = {metric_fn.__class__.__name__: metric_fn}\n",
        "\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE_SGD,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    nesterov=True,\n",
        "    momentum=MOMENTUM_SGD,\n",
        ")\n",
        "# optimizer = torch.optim.AdamW(\n",
        "#     model.parameters(), lr=LEARNING_RATE_ADAM, weight_decay=WEIGHT_DECAY, betas=BETAS_ADAM\n",
        "# )\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer=optimizer,\n",
        "    mode=\"max\",\n",
        "    factor=SCHEDULER_GAMMA,\n",
        "    patience=SCHEDULER_PATIENCE,\n",
        "    min_lr=MIN_LEARNING_RATE,\n",
        ")\n",
        "\n",
        "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
        "checkpointer = CheckpointSaver(\n",
        "    accelerator=accelerator,\n",
        "    model=model,\n",
        "    metric_name=metric_fn.__class__.__name__,\n",
        "    save_dir=CHECKPOINTS_DIR,\n",
        "    rm_save_dir=RM_CHECKPOINTS_DIR,\n",
        "    max_history=5,\n",
        "    should_minimize=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c16bbd-6ca0-4663-ab75-ea46492447b9",
      "metadata": {
        "id": "83c16bbd-6ca0-4663-ab75-ea46492447b9"
      },
      "outputs": [],
      "source": [
        "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
        "tensorboard_logger = torch.utils.tensorboard.SummaryWriter(log_dir=TENSORBOARD_DIR)\n",
        "\n",
        "###################################################\n",
        "# Раскомментировать в Google Colab\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir \"tensorboard\"  --port 6006\n",
        "###################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d830ff9-3e9e-4f0b-995c-128060eee0e9",
      "metadata": {
        "id": "1d830ff9-3e9e-4f0b-995c-128060eee0e9"
      },
      "outputs": [],
      "source": [
        "model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, val_dataloader, lr_scheduler\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1cea82-a47b-4b74-a0e5-22de5bd3c9f4",
      "metadata": {
        "scrolled": true,
        "id": "2f1cea82-a47b-4b74-a0e5-22de5bd3c9f4"
      },
      "outputs": [],
      "source": [
        "train(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    train_dataloader=train_dataloader,\n",
        "    val_dataloader=val_dataloader,\n",
        "    loss_fn=loss_fn,\n",
        "    metric_fns=metric_fns,\n",
        "    lr_scheduler=lr_scheduler,\n",
        "    accelerator=accelerator,\n",
        "    epoch_num=EPOCH_NUM,\n",
        "    checkpointer=checkpointer,\n",
        "    tb_logger=tensorboard_logger,\n",
        "    save_on_val=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51fab484-d2b8-40db-a141-4d7c4eaeb8e8",
      "metadata": {
        "id": "51fab484-d2b8-40db-a141-4d7c4eaeb8e8"
      },
      "source": [
        "## Загрузим и протестируем обученную модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8beaea3-83c6-4f8f-a3f4-392898f18ee4",
      "metadata": {
        "scrolled": true,
        "id": "c8beaea3-83c6-4f8f-a3f4-392898f18ee4"
      },
      "outputs": [],
      "source": [
        "CHECKPOINTS_DIR = \"checkpoints\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# model = UNet(in_channels=3, out_channels=CLASSES_NUM)\n",
        "model = CustomUNet(backbone_name=BACKBONE_NAME, classes_num=CLASSES_NUM)\n",
        "# model = deeplabv3plus_resnet50()\n",
        "\n",
        "model = load_checkpoint(\n",
        "    model=model,\n",
        "    load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\"),\n",
        ")\n",
        "model = model.to(DEVICE)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a64c5c6b-7631-4816-93cb-8156f055810c",
      "metadata": {
        "id": "a64c5c6b-7631-4816-93cb-8156f055810c"
      },
      "outputs": [],
      "source": [
        "sample_idx = 10\n",
        "image, target = val_dataset[sample_idx]\n",
        "\n",
        "preds = torch.argmax(model(image.unsqueeze(0).to(DEVICE)).squeeze(0), axis=0)\n",
        "\n",
        "image = image * STD[:, None, None] + MEAN[:, None, None]\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(9, 18))\n",
        "ax[0].imshow(image.numpy().transpose(1, 2, 0))\n",
        "ax[1].imshow(convert_label_to_color(target.numpy()))\n",
        "ax[2].imshow(convert_label_to_color(preds.cpu().numpy()));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc82364-40d1-4a15-9639-918fa016267f",
      "metadata": {
        "id": "1cc82364-40d1-4a15-9639-918fa016267f"
      },
      "source": [
        "## Разметка данных с помощью CVAT\n",
        "\n",
        "Сайт: https://www.cvat.ai/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0078539-e63a-453e-9e9e-a29e1fec4dcb",
      "metadata": {
        "id": "f0078539-e63a-453e-9e9e-a29e1fec4dcb"
      },
      "source": [
        "## Обзоры бекбонов\n",
        "\n",
        "- Обзор до ~2020: https://arxiv.org/pdf/2206.08016.pdf\n",
        "- Чуть поновее: https://arxiv.org/pdf/2310.19909.pdf\n",
        "- Трансформеры и VLM позже"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2687d96d-94b2-4416-ac20-872bd48e9edf",
      "metadata": {
        "id": "2687d96d-94b2-4416-ac20-872bd48e9edf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}